# -*- coding: utf-8 -*-
"""Projet_Capstone_DS_5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AAudvZ5BY39iPMTDj1-og8xdzFmHPfhz
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.svm import SVC
from xgboost import XGBClassifier
import warnings
warnings.filterwarnings('ignore')

# Configuration de la page
st.set_page_config(
    page_title="Système de Maintenance Prédictive IoT",
    page_icon="🏭",
    layout="wide"
)

# --- CLASSE SYSTÈME D'ALERTE INTELLIGENT ---
class IntelligentAlertSystem:
    def __init__(self, model, features):
        self.model = model
        self.features = features
        self.alert_history = {}

    def predict_with_confidence(self, sensor_data):
        """Prédiction avec niveau de confiance"""
        input_data = pd.DataFrame([sensor_data])[self.features]
        prediction = self.model.predict(input_data)[0]
        probabilities = self.model.predict_proba(input_data)[0]
        confidence = np.max(probabilities)
        class_names = self.model.classes_
        proba_dict = dict(zip(class_names, probabilities))
        return prediction, confidence, proba_dict

    def evaluate_risk(self, sensor_id, prediction, confidence, sensor_data):
        """Évaluation du niveau de risque"""
        risk_levels = {
            'HIGH': {'threshold': 0.85, 'action': 'MAINTENANCE IMMÉDIATE'},
            'MEDIUM': {'threshold': 0.70, 'action': 'SURVEILLANCE RENFORCÉE'},
            'LOW': {'threshold': 0.50, 'action': 'MONITORING STANDARD'}
        }

        if prediction != 'None' and confidence > risk_levels['HIGH']['threshold']:
            risk_level = 'HIGH'
        elif prediction != 'None' and confidence > risk_levels['MEDIUM']['threshold']:
            risk_level = 'MEDIUM'
        elif prediction != 'None':
            risk_level = 'LOW'
        else:
            risk_level = 'SAFE'

        recommendations = self._generate_recommendations(prediction, sensor_data)

        return {
            'sensor_id': sensor_id,
            'prediction': prediction,
            'confidence': confidence,
            'risk_level': risk_level,
            'action': risk_levels.get(risk_level, {}).get('action', 'AUCUNE'),
            'recommendations': recommendations
        }

    def _generate_recommendations(self, prediction, sensor_data):
        """Génération de recommandations personnalisées"""
        recommendations = {
            'None': [
                "✅ Système opérationnel",
                "📅 Maintenance planifiée normale",
                "🔍 Vérification de routine programmée"
            ],
            'Electrical Fault': [
                "🔌 Vérifier l'alimentation électrique",
                "🔎 Inspecter les connexions et câbles",
                "⚡ Contrôler la stabilité de tension",
                "📊 Analyser les variations de courant"
            ],
            'Mechanical Failure': [
                "🛑 Arrêt immédiat recommandé",
                "🔧 Inspection mécanique complète",
                "📊 Vérifier l'usure des composants",
                "🎯 Contrôle des niveaux de vibration"
            ],
            'Overheating': [
                "🌡️ Réduire la charge immédiatement",
                "❄️ Vérifier le système de refroidissement",
                "🔥 Nettoyer les ventilateurs et radiateurs",
                "📈 Surveiller la tendance température"
            ]
        }
        return recommendations.get(prediction, ["🔍 Diagnostic à approfondir"])

# --- GÉNÉRATION DE DONNÉES SIMULÉES ---
def generate_sample_data():
    """Génère des données IoT simulées basées sur votre projet"""
    np.random.seed(42)

    n_samples = 5000
    data = {
        'Sensor_ID': [f'SENSOR_{i:03d}' for i in range(n_samples)],
        'Temperature': np.random.normal(65, 15, n_samples),
        'Vibration': np.random.gamma(2, 2, n_samples),
        'Pressure': np.random.normal(100, 20, n_samples),
        'Voltage': np.random.normal(220, 10, n_samples),
        'Current': np.random.normal(15, 3, n_samples),
        'FFT_Feature1': np.random.uniform(0, 1, n_samples),
        'FFT_Feature2': np.random.uniform(0, 1, n_samples),
        'Timestamp': pd.date_range('2024-01-01', periods=n_samples, freq='H')
    }

    df = pd.DataFrame(data)

    # Génération des défauts basée sur des seuils réalistes
    conditions = [
        (df['Temperature'] > 85) & (df['Voltage'] < 210),
        (df['Vibration'] > 8) & (df['Pressure'] > 130),
        (df['Temperature'] > 90),
        (df['Current'] > 20)
    ]
    choices = ['Electrical Fault', 'Mechanical Failure', 'Overheating', 'Electrical Fault']

    df['Fault_Type'] = np.select(conditions, choices, default='None')
    df['Fault_Status'] = (df['Fault_Type'] != 'None').astype(int)
    df['Anomaly_Score'] = np.random.uniform(0, 1, n_samples)

    return df

# --- PRÉPARATION DES DONNÉES ET ENTRAÎNEMENT ---
@st.cache_resource
def load_model_and_data():
    """Charge et entraîne le modèle avec mise en cache"""
    st.info("🎯 Génération des données et entraînement du modèle...")

    # Génération des données
    df_clean = generate_sample_data()

    # Feature engineering avancé (basé sur votre projet)
    df_clean['Timestamp'] = pd.to_datetime(df_clean['Timestamp'])
    df_clean['hour'] = df_clean['Timestamp'].dt.hour

    # Features composites (Cellule 13 de votre projet)
    df_clean['thermal_stress'] = df_clean['Temperature'] * df_clean['Current'] / 1000
    df_clean['mechanical_stress'] = df_clean['Vibration'] * df_clean['Pressure'] / 1000
    df_clean['power_consumption'] = df_clean['Voltage'] * df_clean['Current']

    # Normalisation des features
    for col in ['Temperature', 'Vibration', 'Pressure', 'Voltage', 'Current']:
        df_clean[f'Normalized_{col}'] = (
            df_clean[col] - df_clean[col].mean()
        ) / df_clean[col].std()

    # Features finales (basées sur votre projet)
    features = [
        'Temperature', 'Vibration', 'Pressure', 'Voltage', 'Current',
        'FFT_Feature1', 'FFT_Feature2', 'Anomaly_Score',
        'Normalized_Temp', 'Normalized_Vibration', 'Normalized_Pressure',
        'Normalized_Voltage', 'Normalized_Current', 'hour',
        'thermal_stress', 'mechanical_stress', 'power_consumption'
    ]

    X = df_clean[features]
    y = df_clean['Fault_Type']

    # Modèle ensemble (Random Forest + XGBoost + SVM)
    rf_model = RandomForestClassifier(
        n_estimators=200,
        max_depth=20,
        min_samples_split=2,
        min_samples_leaf=1,
        random_state=42,
        n_jobs=-1
    )

    xgb_model = XGBClassifier(
        n_estimators=150,
        learning_rate=0.1,
        max_depth=6,
        random_state=42
    )

    svm_model = SVC(
        kernel='rbf',
        probability=True,
        random_state=42
    )

    ensemble_model = VotingClassifier(
        estimators=[
            ('rf', rf_model),
            ('xgb', xgb_model),
            ('svm', svm_model)
        ],
        voting='soft'
    )

    # Entraînement
    ensemble_model.fit(X, y)

    # Système d'alerte
    alert_system = IntelligentAlertSystem(ensemble_model, features)

    st.success("✅ Modèle entraîné avec succès !")
    return alert_system, df_clean, ensemble_model, features

# --- INTERFACE STREAMLIT ---
def main():
    st.title("🏭 Système de Maintenance Prédictive pour Équipements IoT")
    st.markdown("**Projet Capstone Data Science - Basé sur votre analyse complète**")

    # Sidebar avec informations
    with st.sidebar:
        st.header("📊 À propos")
        st.markdown("""
        **Technologies utilisées :**
        - Python, Scikit-learn, XGBoost
        - Random Forest, SVM, Modèle Ensemble
        - Streamlit pour l'interface

        **Types de défauts détectés :**
        - ✅ Aucun défaut
        - 🔌 Défaut électrique
        - 🔧 Défaut mécanique
        - 🌡️ Surchauffe
        """)

        st.header("🎯 Objectifs")
        st.markdown("""
        - Classification multi-classes
        - Détection temps réel
        - Réduction des coûts de maintenance
        - Alertes intelligentes
        """)

    # Chargement du modèle
    alert_system, df_demo, model, features = load_model_and_data()

    # Onglets principaux
    tab1, tab2, tab3, tab4 = st.tabs([
        "🔍 Prédiction Temps Réel",
        "📊 Analyse des Données",
        "📈 Performance Modèle",
        "🚨 Historique Alertes"
    ])

    with tab1:
        st.header("Prédiction en Temps Réel")

        col1, col2 = st.columns([1, 1])

        with col1:
            st.subheader("📈 Paramètres du Capteur")

            # Sélection de scénarios prédéfinis
            scenario = st.selectbox(
                "Choisir un scénario :",
                [
                    "🎯 Normal (Optimal)",
                    "⚠️ Défaut Électrique",
                    "🔧 Défaut Mécanique",
                    "🌡️ Surchauffe",
                    "🔧 Personnalisé"
                ]
            )

            # Valeurs par défaut selon le scénario
            if scenario == "🎯 Normal (Optimal)":
                temp, vib, press, volt, curr = 65.0, 3.5, 95.0, 220.0, 15.0
            elif scenario == "⚠️ Défaut Électrique":
                temp, vib, press, volt, curr = 75.0, 4.0, 110.0, 190.0, 22.0
            elif scenario == "🔧 Défaut Mécanique":
                temp, vib, press, volt, curr = 70.0, 9.5, 140.0, 215.0, 16.0
            elif scenario == "🌡️ Surchauffe":
                temp, vib, press, volt, curr = 92.0, 5.0, 105.0, 225.0, 18.0
            else:
                temp, vib, press, volt, curr = 65.0, 3.5, 95.0, 220.0, 15.0

            # Contrôles des paramètres
            temperature = st.slider("🌡️ Temperature (°C)", 20.0, 120.0, temp, 0.1)
            vibration = st.slider("📊 Vibration (m/s²)", 0.0, 15.0, vib, 0.1)
            pressure = st.slider("💨 Pressure (kPa)", 50.0, 200.0, press, 0.1)
            voltage = st.slider("⚡ Voltage (V)", 180.0, 250.0, volt, 0.1)
            current = st.slider("🔋 Current (A)", 5.0, 25.0, curr, 0.1)

            sensor_id = st.text_input("🔧 ID du Capteur", "SENSOR_001")

        with col2:
            st.subheader("🎯 Résultats du Diagnostic")

            if st.button("🚀 Lancer l'Analyse", type="primary", use_container_width=True):
                # Préparation des données de capteur
                sensor_data = {
                    'Temperature': temperature,
                    'Vibration': vibration,
                    'Pressure': pressure,
                    'Voltage': voltage,
                    'Current': current,
                    'FFT_Feature1': np.random.uniform(0, 1),
                    'FFT_Feature2': np.random.uniform(0, 1),
                    'Anomaly_Score': np.random.uniform(0, 1),
                    'hour': pd.Timestamp.now().hour,
                    'thermal_stress': temperature * current / 1000,
                    'mechanical_stress': vibration * pressure / 1000,
                    'power_consumption': voltage * current
                }

                # Ajout des features normalisées
                for col in ['Temperature', 'Vibration', 'Pressure', 'Voltage', 'Current']:
                    sensor_data[f'Normalized_{col}'] = 0.0  # Simplifié pour la démo

                # Prédiction
                with st.spinner("🔍 Analyse en cours..."):
                    prediction, confidence, proba_dict = alert_system.predict_with_confidence(sensor_data)
                    alert_info = alert_system.evaluate_risk(sensor_id, prediction, confidence, sensor_data)

                # Affichage des résultats
                st.subheader("📋 Diagnostic Complet")

                # Métriques principales
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Prédiction", alert_info['prediction'])
                with col2:
                    risk_color = {
                        'HIGH': '🔴', 'MEDIUM': '🟡', 'LOW': '🔵', 'SAFE': '🟢'
                    }
                    st.metric("Niveau de Risque",
                             f"{risk_color.get(alert_info['risk_level'], '⚪')} {alert_info['risk_level']}")
                with col3:
                    st.metric("Confiance", f"{alert_info['confidence']:.1%}")

                # Alerte colorée
                if alert_info['risk_level'] == 'HIGH':
                    st.error(f"🚨 **{alert_info['action']}**")
                elif alert_info['risk_level'] == 'MEDIUM':
                    st.warning(f"⚠️ **{alert_info['action']}**")
                elif alert_info['risk_level'] == 'LOW':
                    st.info(f"ℹ️ **{alert_info['action']}**")
                else:
                    st.success(f"✅ **{alert_info['action']}**")

                # Recommandations
                with st.expander("📋 Recommandations détaillées", expanded=True):
                    for i, rec in enumerate(alert_info['recommendations'], 1):
                        st.write(f"{i}. {rec}")

                # Probabilités
                with st.expander("📊 Probabilités par type de défaut"):
                    prob_df = pd.DataFrame(proba_dict, index=['Probabilité']).T
                    prob_df_sorted = prob_df.sort_values('Probabilité', ascending=False)
                    st.dataframe(prob_df_sorted.style.format("{:.1%}"))

                    # Graphique des probabilités
                    fig, ax = plt.subplots(figsize=(10, 4))
                    prob_df_sorted.plot(kind='bar', ax=ax, color='skyblue')
                    ax.set_title('Distribution des Probabilités de Défaut')
                    ax.set_ylabel('Probabilité')
                    ax.tick_params(axis='x', rotation=45)
                    st.pyplot(fig)

    with tab2:
        st.header("Analyse des Données")

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("📈 Distribution des Défauts")
            fault_dist = df_demo['Fault_Type'].value_counts()

            fig, ax = plt.subplots(figsize=(8, 6))
            ax.pie(fault_dist.values, labels=fault_dist.index, autopct='%1.1f%%', startangle=90)
            ax.set_title('Répartition des Types de Défauts')
            st.pyplot(fig)

        with col2:
            st.subheader("📊 Statistiques Descriptives")
            st.dataframe(df_demo[['Temperature', 'Vibration', 'Pressure', 'Voltage', 'Current']].describe())

        # Corrélations
        st.subheader("🔗 Matrice de Corrélation")
        numeric_cols = ['Temperature', 'Vibration', 'Pressure', 'Voltage', 'Current', 'Anomaly_Score']
        corr_matrix = df_demo[numeric_cols].corr()

        fig, ax = plt.subplots(figsize=(10, 8))
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=ax)
        ax.set_title('Matrice de Corrélation')
        st.pyplot(fig)

    with tab3:
        st.header("Performance du Modèle")

        # Évaluation du modèle
        X = df_demo[features]
        y = df_demo['Fault_Type']
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Accuracy", f"{accuracy:.1%}")
        with col2:
            st.metric("Nombre d'échantillons", len(df_demo))
        with col3:
            st.metric("Nombre de features", len(features))

        # Matrice de confusion
        st.subheader("📋 Matrice de Confusion")
        cm = confusion_matrix(y_test, y_pred, labels=model.classes_)

        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_, ax=ax)
        ax.set_xlabel('Prédit')
        ax.set_ylabel('Réel')
        ax.set_title('Matrice de Confusion')
        st.pyplot(fig)

        # Rapport de classification
        st.subheader("📊 Rapport de Classification")
        report = classification_report(y_test, y_pred, output_dict=True)
        report_df = pd.DataFrame(report).transpose()
        st.dataframe(report_df.style.format("{:.2f}"))

    with tab4:
        st.header("Historique des Alertes")
        st.info("📈 Fonctionnalité en cours de développement...")

        # Simulation d'historique
        history_data = {
            'Date': pd.date_range('2024-01-01', periods=10, freq='D'),
            'Capteur': [f'SENSOR_{i:03d}' for i in range(10)],
            'Type Défaut': ['None', 'Electrical Fault', 'None', 'Overheating', 'None',
                           'Mechanical Failure', 'None', 'None', 'Electrical Fault', 'None'],
            'Niveau Risque': ['SAFE', 'HIGH', 'SAFE', 'MEDIUM', 'SAFE',
                             'HIGH', 'SAFE', 'SAFE', 'MEDIUM', 'SAFE'],
            'Confiance': [0.95, 0.89, 0.92, 0.76, 0.88, 0.91, 0.94, 0.90, 0.78, 0.93]
        }

        history_df = pd.DataFrame(history_data)
        st.dataframe(history_df)

        # Graphique des alertes
        fig, ax = plt.subplots(figsize=(10, 4))
        alert_counts = history_df['Niveau Risque'].value_counts()
        alert_counts.plot(kind='bar', color=['green', 'red', 'orange', 'blue'], ax=ax)
        ax.set_title('Distribution des Niveaux de Risque')
        ax.set_ylabel('Nombre d\'alertes')
        st.pyplot(fig)

# --- FOOTER ---
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center'>
        <p><strong>Projet Capstone Data Science - Maintenance Prédictive IoT</strong></p>
        <p>Développé avec ❤️ using Streamlit | Basé sur l'analyse complète du dataset IoT</p>
    </div>
    """,
    unsafe_allow_html=True
)

if __name__ == "__main__":
    main()
