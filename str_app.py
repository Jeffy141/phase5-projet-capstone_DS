import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

# Configuration de la page
st.set_page_config(
    page_title="SystÃ¨me de Maintenance PrÃ©dictive IoT",
    page_icon="ğŸ­",
    layout="wide"
)

# Style pour les graphiques
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

# --- CLASSE SYSTÃˆME D'ALERTE INTELLIGENT ---
class IntelligentAlertSystem:
    def __init__(self, model, features):
        self.model = model
        self.features = features

    def predict_with_confidence(self, sensor_data):
        """PrÃ©diction avec niveau de confiance"""
        input_dict = {}
        for feature in self.features:
            if feature in sensor_data:
                input_dict[feature] = sensor_data[feature]
            else:
                input_dict[feature] = 0.0
        
        input_data = pd.DataFrame([input_dict])[self.features]
        prediction = self.model.predict(input_data)[0]
        probabilities = self.model.predict_proba(input_data)[0]
        confidence = np.max(probabilities)
        class_names = self.model.classes_
        proba_dict = dict(zip(class_names, probabilities))
        return prediction, confidence, proba_dict

    def evaluate_risk(self, sensor_id, prediction, confidence, sensor_data):
        """Ã‰valuation du niveau de risque"""
        risk_levels = {
            'HIGH': {'threshold': 0.85, 'action': 'MAINTENANCE IMMÃ‰DIATE'},
            'MEDIUM': {'threshold': 0.70, 'action': 'SURVEILLANCE RENFORCÃ‰E'},
            'LOW': {'threshold': 0.50, 'action': 'MONITORING STANDARD'}
        }
        
        if prediction != 'None' and confidence > risk_levels['HIGH']['threshold']:
            risk_level = 'HIGH'
        elif prediction != 'None' and confidence > risk_levels['MEDIUM']['threshold']:
            risk_level = 'MEDIUM'
        elif prediction != 'None':
            risk_level = 'LOW'
        else:
            risk_level = 'SAFE'
        
        recommendations = self._generate_recommendations(prediction, sensor_data)
        
        return {
            'sensor_id': sensor_id,
            'prediction': prediction,
            'confidence': confidence,
            'risk_level': risk_level,
            'action': risk_levels.get(risk_level, {}).get('action', 'AUCUNE'),
            'recommendations': recommendations
        }

    def _generate_recommendations(self, prediction, sensor_data):
        """GÃ©nÃ©ration de recommandations personnalisÃ©es"""
        recommendations = {
            'None': ["âœ… SystÃ¨me opÃ©rationnel", "ğŸ“… Maintenance planifiÃ©e normale"],
            'Electrical Fault': [
                "ğŸ”Œ VÃ©rifier l'alimentation Ã©lectrique",
                "ğŸ” Inspecter les connexions",
                "âš¡ ContrÃ´ler la stabilitÃ© de tension"
            ],
            'Mechanical Failure': [
                "ğŸ›‘ ArrÃªt immÃ©diat recommandÃ©",
                "ğŸ”§ Inspection mÃ©canique complÃ¨te",
                "ğŸ“Š VÃ©rifier l'usure des composants"
            ],
            'Overheating': [
                "ğŸŒ¡ï¸ RÃ©duire la charge immÃ©diatement",
                "â„ï¸ VÃ©rifier le systÃ¨me de refroidissement",
                "ğŸ”¥ TempÃ©rature critique dÃ©tectÃ©e"
            ]
        }
        return recommendations.get(prediction, ["ğŸ” Diagnostic Ã  approfondir"])

# --- GESTION DES DONNÃ‰ES AVEC SUPPORT FRANÃ‡AIS ---
def find_csv_file():
    """Cherche le fichier CSV dans diffÃ©rents noms possibles"""
    import os
    possible_files = [
        'ensemble_de_donnees_de_surveillance_iot.csv',  # Nom franÃ§ais
        'iot_equipment_monitoring_dataset.csv',         # Nom anglais
       
    ]
    
    for file_name in possible_files:
        if os.path.exists(file_name):
            st.info(f"ğŸ“ Fichier trouvÃ©: {file_name}")
            return file_name
    
    return None

def generate_sample_data():
    """GÃ©nÃ¨re des donnÃ©es IoT simulÃ©es complÃ¨tes"""
    np.random.seed(42)
    n_samples = 1000
    
    data = {
        'Sensor_ID': [f'SENSOR_{i:03d}' for i in range(n_samples)],
        'Temperature': np.random.normal(65, 15, n_samples),
        'Vibration': np.random.gamma(2, 2, n_samples),
        'Pressure': np.random.normal(100, 20, n_samples),
        'Voltage': np.random.normal(220, 10, n_samples),
        'Current': np.random.normal(15, 3, n_samples),
        'FFT_Feature1': np.random.uniform(0, 1, n_samples),
        'FFT_Feature2': np.random.uniform(0, 1, n_samples),
        'Anomaly_Score': np.random.uniform(0, 1, n_samples),
        'Timestamp': pd.date_range('2024-01-01', periods=n_samples, freq='H')
    }
    
    df = pd.DataFrame(data)
    
    # GÃ©nÃ©ration des dÃ©fauts
    conditions = [
        (df['Temperature'] > 85) & (df['Voltage'] < 210),
        (df['Vibration'] > 8) & (df['Pressure'] > 130),
        (df['Temperature'] > 90),
        (df['Current'] > 20)
    ]
    choices = ['Electrical Fault', 'Mechanical Failure', 'Overheating', 'Electrical Fault']
    
    df['Fault_Type'] = np.select(conditions, choices, default='None')
    df['Fault_Status'] = (df['Fault_Type'] != 'None').astype(int)
    
    return df

@st.cache_data
def load_csv_data():
    """Charge le fichier CSV avec gestion multi-noms"""
    import os
    
    # Chercher le fichier CSV
    csv_file = find_csv_file()
    
    if csv_file is None:
        st.warning("ğŸ“ Aucun fichier CSV trouvÃ©. GÃ©nÃ©ration de donnÃ©es simulÃ©es...")
        return generate_sample_data()
    
    try:
        # Essayer de lire le fichier
        st.info(f"ğŸ”„ Lecture du fichier: {csv_file}")
        df = pd.read_csv(csv_file)
        
        # VÃ©rifier si le fichier est vide
        if df.empty:
            st.warning("ğŸ“ Fichier CSV trouvÃ© mais vide. GÃ©nÃ©ration de donnÃ©es simulÃ©es...")
            return generate_sample_data()
        
        # VÃ©rifier s'il y a des colonnes
        if df.shape[1] == 0:
            st.warning("ğŸ“ Fichier CSV sans colonnes. GÃ©nÃ©ration de donnÃ©es simulÃ©es...")
            return generate_sample_data()
            
        st.success(f"âœ… Fichier CSV chargÃ© : {df.shape[0]} lignes, {df.shape[1]} colonnes")
        
        # Afficher les premiÃ¨res colonnes pour debug
        st.info(f"ğŸ“Š Colonnes dÃ©tectÃ©es: {list(df.columns[:8])}...")
        
        return df
        
    except pd.errors.EmptyDataError:
        st.warning("ğŸ“ Fichier CSV vide. GÃ©nÃ©ration de donnÃ©es simulÃ©es...")
        return generate_sample_data()
    except Exception as e:
        st.warning(f"ğŸ“ Erreur de lecture du CSV ({e}). GÃ©nÃ©ration de donnÃ©es simulÃ©es...")
        return generate_sample_data()

# --- CHARGEMENT DU MODÃˆLE AMÃ‰LIORÃ‰ ---
@st.cache_resource
def load_model_and_data():
    """Charge et entraÃ®ne le modÃ¨le avec gestion des donnÃ©es rÃ©elles"""
    st.info("ğŸ¯ Chargement des donnÃ©es et entraÃ®nement du modÃ¨le...")
    
    # Charger les donnÃ©es (rÃ©elles ou simulÃ©es)
    df_raw = load_csv_data()
    df_clean = df_raw.copy()
    
    # Mapping des colonnes franÃ§aises vers anglaises
    column_mapping = {
        'Capteur_ID': 'Sensor_ID',
        'TempÃ©rature': 'Temperature', 
        'Vibration': 'Vibration',
        'Pression': 'Pressure',
        'Tension': 'Voltage',
        'Courant': 'Current',
        'Type_Defaut': 'Fault_Type',
        'Statut_Defaut': 'Fault_Status',
        'Horodatage': 'Timestamp'
    }
    
    # Renommer les colonnes franÃ§aises si elles existent
    for fr_col, en_col in column_mapping.items():
        if fr_col in df_clean.columns and en_col not in df_clean.columns:
            df_clean[en_col] = df_clean[fr_col]
            st.info(f"ğŸ”„ Colonne renommÃ©e: {fr_col} -> {en_col}")
    
    # VÃ©rifier et crÃ©er les colonnes essentielles si manquantes
    essential_columns = ['Sensor_ID', 'Temperature', 'Vibration', 'Pressure', 'Voltage', 'Current', 'Fault_Type']
    for col in essential_columns:
        if col not in df_clean.columns:
            if col == 'Sensor_ID':
                df_clean[col] = [f'SENSOR_{i:03d}' for i in range(len(df_clean))]
            elif col == 'Fault_Type':
                df_clean[col] = 'None'
            else:
                df_clean[col] = 0.0
            st.warning(f"âš ï¸ Colonne '{col}' manquante, crÃ©ation avec valeurs par dÃ©faut")
    
    # Feature engineering
    if 'Timestamp' in df_clean.columns:
        df_clean['Timestamp'] = pd.to_datetime(df_clean['Timestamp'])
        df_clean['hour'] = df_clean['Timestamp'].dt.hour
    else:
        df_clean['hour'] = 12
    
    # Features composites
    df_clean['thermal_stress'] = df_clean['Temperature'] * df_clean['Current'] / 1000
    df_clean['mechanical_stress'] = df_clean['Vibration'] * df_clean['Pressure'] / 1000
    df_clean['power_consumption'] = df_clean['Voltage'] * df_clean['Current']
    
    # Normalisation des features
    for col in ['Temperature', 'Vibration', 'Pressure', 'Voltage', 'Current']:
        if col in df_clean.columns:
            df_clean[f'Normalized_{col}'] = (
                df_clean[col] - df_clean[col].mean()
            ) / df_clean[col].std()
        else:
            df_clean[f'Normalized_{col}'] = 0.0

    # Features finales
    features = [
        'Temperature', 'Vibration', 'Pressure', 'Voltage', 'Current',
        'FFT_Feature1', 'FFT_Feature2', 'Anomaly_Score',
        'Normalized_Temperature', 'Normalized_Vibration', 'Normalized_Pressure',
        'Normalized_Voltage', 'Normalized_Current', 'hour',
        'thermal_stress', 'mechanical_stress', 'power_consumption'
    ]
    
    # VÃ©rification que toutes les features existent
    missing_features = [f for f in features if f not in df_clean.columns]
    if missing_features:
        st.warning(f"Features manquantes crÃ©Ã©es: {missing_features}")
        for feature in missing_features:
            df_clean[feature] = 0.0
    
    X = df_clean[features]
    y = df_clean['Fault_Type']

    # ModÃ¨le ensemble
    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
    xgb_model = XGBClassifier(random_state=42)
    svm_model = SVC(probability=True, random_state=42)
    
    ensemble_model = VotingClassifier(
        estimators=[
            ('rf', rf_model),
            ('xgb', xgb_model),
            ('svm', svm_model)
        ],
        voting='soft'
    )

    # EntraÃ®nement avec progression
    with st.spinner("ğŸ¤– EntraÃ®nement du modÃ¨le en cours..."):
        ensemble_model.fit(X, y)
    
    # SystÃ¨me d'alerte
    alert_system = IntelligentAlertSystem(ensemble_model, features)
    
    st.success("âœ… ModÃ¨le entraÃ®nÃ© avec succÃ¨s !")
    return alert_system, df_clean, ensemble_model, features, X, y

# --- FONCTIONS DE VISUALISATION ---
def create_confusion_matrix(model, X, y):
    """CrÃ©e la matrice de confusion"""
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    y_pred = model.predict(X_test)
    
    fig, ax = plt.subplots(figsize=(8, 6))
    cm = confusion_matrix(y_test, y_pred, labels=model.classes_)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_, ax=ax)
    ax.set_title('Matrice de Confusion', fontsize=14, fontweight='bold')
    ax.set_xlabel('PrÃ©dictions')
    ax.set_ylabel('Valeurs RÃ©elles')
    return fig

def create_feature_importance(model, features):
    """CrÃ©e le graphique d'importance des features"""
    if hasattr(model.estimators_[0], 'feature_importances_'):
        importances = model.estimators_[0].feature_importances_
    else:
        importances = np.ones(len(features)) / len(features)
    
    feature_imp = pd.DataFrame({
        'feature': features,
        'importance': importances
    }).sort_values('importance', ascending=False)
    
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.barplot(data=feature_imp.head(10), y='feature', x='importance', ax=ax)
    ax.set_title('Top 10 - Importance des Variables', fontsize=14, fontweight='bold')
    ax.set_xlabel('Importance')
    return fig, feature_imp

def create_fault_distribution(df):
    """CrÃ©e la distribution des dÃ©fauts"""
    fault_counts = df['Fault_Type'].value_counts()
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    # Camembert
    colors = ['lightgreen', 'red', 'orange', 'yellow']
    ax1.pie(fault_counts.values, labels=fault_counts.index, autopct='%1.1f%%', 
            colors=colors[:len(fault_counts)], startangle=90)
    ax1.set_title('Distribution des Types de DÃ©fauts')
    
    # Barres
    sns.barplot(x=fault_counts.index, y=fault_counts.values, ax=ax2, palette=colors[:len(fault_counts)])
    ax2.set_title('Nombre de DÃ©fauts par Type')
    ax2.tick_params(axis='x', rotation=45)
    
    plt.tight_layout()
    return fig

# --- INTERFACE UTILISATEUR AMÃ‰LIORÃ‰E ---
def main():
    st.title("ğŸ­ SystÃ¨me de Maintenance PrÃ©dictive IoT")
    st.markdown("**Projet Capstone - PrÃ©sentation ComplÃ¨te avec Visualisations**")
    
    # Barre de progression
    with st.expander("ğŸ¯ Statut du Chargement", expanded=True):
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # Chargement du modÃ¨le
        try:
            status_text.text("ğŸ” Recherche des donnÃ©es...")
            progress_bar.progress(25)
            
            alert_system, df_clean, model, features, X, y = load_model_and_data()
            
            status_text.text("âœ… DonnÃ©es chargÃ©es avec succÃ¨s!")
            progress_bar.progress(100)
            
        except Exception as e:
            st.error(f"Erreur lors du chargement : {e}")
            return
    
    # Supprimer la barre de progression aprÃ¨s chargement
    progress_bar.empty()
    status_text.empty()
    
    # Onglets pour une meilleure organisation
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ” Simulation Temps RÃ©el", 
        "ğŸ“Š Analyse des DonnÃ©es", 
        "ğŸ¤– Performance du ModÃ¨le",
        "ğŸ“ˆ Visualisations PrÃ©sentation"
    ])
    
    with tab1:
        st.header("ğŸ” Simulation de PrÃ©diction en Temps RÃ©el")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ“Š ParamÃ¨tres du Capteur")
            
            # SÃ©lection de scÃ©narios
            scenario = st.selectbox(
                "Choisir un scÃ©nario :",
                ["ğŸ¯ Normal", "âš ï¸ DÃ©faut Ã‰lectrique", "ğŸ”§ DÃ©faut MÃ©canique", "ğŸŒ¡ï¸ Surchauffe"]
            )
            
            # Valeurs par dÃ©faut selon le scÃ©nario
            if scenario == "ğŸ¯ Normal":
                temp, vib, press, volt, curr = 65.0, 3.5, 95.0, 220.0, 15.0
            elif scenario == "âš ï¸ DÃ©faut Ã‰lectrique":
                temp, vib, press, volt, curr = 75.0, 4.0, 110.0, 190.0, 22.0
            elif scenario == "ğŸ”§ DÃ©faut MÃ©canique":
                temp, vib, press, volt, curr = 70.0, 9.5, 140.0, 215.0, 16.0
            else:  # Surchauffe
                temp, vib, press, volt, curr = 92.0, 5.0, 105.0, 225.0, 18.0
            
            temperature = st.slider("ğŸŒ¡ï¸ Temperature (Â°C)", 20.0, 120.0, temp, 0.1)
            vibration = st.slider("ğŸ“Š Vibration (m/sÂ²)", 0.0, 15.0, vib, 0.1)
            pressure = st.slider("ğŸ’¨ Pressure (kPa)", 50.0, 200.0, press, 0.1)
            voltage = st.slider("âš¡ Voltage (V)", 180.0, 250.0, volt, 0.1)
            current = st.slider("ğŸ”‹ Current (A)", 5.0, 25.0, curr, 0.1)
        
        with col2:
            st.subheader("ğŸ¯ RÃ©sultats du Diagnostic")
            
            if st.button("ğŸš€ Lancer le Diagnostic", type="primary", use_container_width=True):
                # PrÃ©paration des donnÃ©es de capteur
                sensor_data = {}
                for feature in features:
                    if feature == 'Temperature': 
                        sensor_data[feature] = temperature
                    elif feature == 'Vibration': 
                        sensor_data[feature] = vibration
                    elif feature == 'Pressure': 
                        sensor_data[feature] = pressure
                    elif feature == 'Voltage': 
                        sensor_data[feature] = voltage
                    elif feature == 'Current': 
                        sensor_data[feature] = current
                    elif feature == 'thermal_stress': 
                        sensor_data[feature] = temperature * current / 1000
                    elif feature == 'mechanical_stress': 
                        sensor_data[feature] = vibration * pressure / 1000
                    elif feature == 'power_consumption': 
                        sensor_data[feature] = voltage * current
                    elif feature == 'hour': 
                        sensor_data[feature] = pd.Timestamp.now().hour
                    else: 
                        sensor_data[feature] = np.random.uniform(0, 1)
                
                # PrÃ©diction
                with st.spinner("ğŸ” Analyse en cours..."):
                    try:
                        prediction, confidence, proba_dict = alert_system.predict_with_confidence(sensor_data)
                        alert_info = alert_system.evaluate_risk("SENSOR_001", prediction, confidence, sensor_data)
                    except Exception as e:
                        st.error(f"Erreur lors de la prÃ©diction : {e}")
                        return
                
                # Affichage des rÃ©sultats
                st.subheader("ğŸ“‹ Diagnostic Complet")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("PrÃ©diction", alert_info['prediction'])
                with col2:
                    risk_color = {
                        'HIGH': 'ğŸ”´', 'MEDIUM': 'ğŸŸ¡', 'LOW': 'ğŸ”µ', 'SAFE': 'ğŸŸ¢'
                    }
                    st.metric("Niveau de Risque", 
                             f"{risk_color.get(alert_info['risk_level'], 'âšª')} {alert_info['risk_level']}")
                with col3:
                    st.metric("Confiance", f"{alert_info['confidence']:.1%}")
                
                # Alerte colorÃ©e
                if alert_info['risk_level'] == 'HIGH':
                    st.error(f"ğŸš¨ **{alert_info['action']}**")
                elif alert_info['risk_level'] == 'MEDIUM':
                    st.warning(f"âš ï¸ **{alert_info['action']}**")
                elif alert_info['risk_level'] == 'LOW':
                    st.info(f"â„¹ï¸ **{alert_info['action']}**")
                else:
                    st.success(f"âœ… **{alert_info['action']}**")
                
                # Recommandations
                with st.expander("ğŸ“‹ Recommandations dÃ©taillÃ©es", expanded=True):
                    for i, rec in enumerate(alert_info['recommendations'], 1):
                        st.write(f"{i}. {rec}")
                
                # ProbabilitÃ©s
                with st.expander("ğŸ“Š ProbabilitÃ©s par type de dÃ©faut"):
                    prob_df = pd.DataFrame(proba_dict, index=['ProbabilitÃ©']).T
                    prob_df_sorted = prob_df.sort_values('ProbabilitÃ©', ascending=False)
                    st.dataframe(prob_df_sorted.style.format("{:.1%}").background_gradient(cmap='RdYlGn_r'))
    
    with tab2:
        st.header("ğŸ“Š Analyse Exploratoire des DonnÃ©es")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Distribution des DÃ©fauts")
            fig_dist = create_fault_distribution(df_clean)
            st.pyplot(fig_dist)
        
        with col2:
            st.subheader("Statistiques Descriptives")
            numeric_cols = ['Temperature', 'Vibration', 'Pressure', 'Voltage', 'Current']
            numeric_cols = [col for col in numeric_cols if col in df_clean.columns]
            st.dataframe(df_clean[numeric_cols].describe().style.background_gradient(cmap='Blues'))
            
            st.subheader("Ã‰chantillon des DonnÃ©es")
            st.dataframe(df_clean.head(10))
    
    with tab3:
        st.header("ğŸ¤– Performance du ModÃ¨le")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Matrice de Confusion")
            fig_cm = create_confusion_matrix(model, X, y)
            st.pyplot(fig_cm)
        
        with col2:
            st.subheader("Importance des Features")
            fig_imp, feature_imp = create_feature_importance(model, features)
            st.pyplot(fig_imp)
            
            st.subheader("Top 10 Features")
            st.dataframe(feature_imp.head(10).style.background_gradient(cmap='Greens'))
    
    with tab4:
        st.header("ğŸ“ˆ Visualisations pour PrÃ©sentation")
        
        st.info("ğŸ¯ **Graphiques prÃªts pour votre prÃ©sentation Capstone**")
        
        # Graphique 1: Distribution des dÃ©fauts
        st.subheader("1. Distribution des Types de DÃ©fauts")
        fig1 = create_fault_distribution(df_clean)
        st.pyplot(fig1)
        
        # Graphique 2: Matrice de confusion
        st.subheader("2. Performance du ModÃ¨le - Matrice de Confusion")
        fig2 = create_confusion_matrix(model, X, y)
        st.pyplot(fig2)
        
        # Graphique 3: Importance des features
        st.subheader("3. Importance des Variables PrÃ©dictives")
        fig3, _ = create_feature_importance(model, features)
        st.pyplot(fig3)

# Sidebar avec informations
with st.sidebar:
    st.header("ğŸ“Š Ã€ propos")
    st.markdown("""
    **Fichiers CSV supportÃ©s:**
    - `ensemble_de_donnees_de_surveillance_iot.csv` ğŸ‡«ğŸ‡·
    - `iot_equipment_monitoring_dataset.csv` ğŸ‡¬ğŸ‡§
    - Autres noms: `donnees_iot.csv`, `data_iot.csv`
    
    **Technologies utilisÃ©es :**
    - Python, Scikit-learn, XGBoost
    - Random Forest, SVM, ModÃ¨le Ensemble
    - Streamlit pour l'interface
    """)
    
    st.header("ğŸ¯ Points ClÃ©s PrÃ©sentation")
    st.markdown("""
    1. **Simulation temps rÃ©el**
    2. **Performance du modÃ¨le** 
    3. **Analyse des donnÃ©es**
    4. **Visualisations professionnelles**
    5. **Recommandations business**
    """)
    
    # Information sur les donnÃ©es chargÃ©es
    try:
        if 'df_clean' in locals():
            st.header("ğŸ“ˆ MÃ©triques")
            st.metric("Nombre d'Ã©chantillons", len(df_clean))
            st.metric("Types de dÃ©fauts", df_clean['Fault_Type'].nunique())
            fault_rate = (df_clean['Fault_Type'] != 'None').mean() * 100
            st.metric("Taux de dÃ©faut", f"{fault_rate:.1f}%")
    except:
        pass

if __name__ == "__main__":
    main()
