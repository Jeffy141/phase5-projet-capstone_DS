# -*- coding: utf-8 -*-
"""Projet_Capstone_DS_5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AAudvZ5BY39iPMTDj1-og8xdzFmHPfhz
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.svm import SVC
from xgboost import XGBClassifier
import warnings
warnings.filterwarnings('ignore')

# Configuration de la page
st.set_page_config(
    page_title="SystÃ¨me de Maintenance PrÃ©dictive IoT",
    page_icon="ğŸ­",
    layout="wide"
)

# --- CLASSE SYSTÃˆME D'ALERTE INTELLIGENT ---
class IntelligentAlertSystem:
    def __init__(self, model, features):
        self.model = model
        self.features = features
        self.alert_history = {}

    def predict_with_confidence(self, sensor_data):
        """PrÃ©diction avec niveau de confiance"""
        input_data = pd.DataFrame([sensor_data])[self.features]
        prediction = self.model.predict(input_data)[0]
        probabilities = self.model.predict_proba(input_data)[0]
        confidence = np.max(probabilities)
        class_names = self.model.classes_
        proba_dict = dict(zip(class_names, probabilities))
        return prediction, confidence, proba_dict

    def evaluate_risk(self, sensor_id, prediction, confidence, sensor_data):
        """Ã‰valuation du niveau de risque"""
        risk_levels = {
            'HIGH': {'threshold': 0.85, 'action': 'MAINTENANCE IMMÃ‰DIATE'},
            'MEDIUM': {'threshold': 0.70, 'action': 'SURVEILLANCE RENFORCÃ‰E'},
            'LOW': {'threshold': 0.50, 'action': 'MONITORING STANDARD'}
        }

        if prediction != 'None' and confidence > risk_levels['HIGH']['threshold']:
            risk_level = 'HIGH'
        elif prediction != 'None' and confidence > risk_levels['MEDIUM']['threshold']:
            risk_level = 'MEDIUM'
        elif prediction != 'None':
            risk_level = 'LOW'
        else:
            risk_level = 'SAFE'

        recommendations = self._generate_recommendations(prediction, sensor_data)

        return {
            'sensor_id': sensor_id,
            'prediction': prediction,
            'confidence': confidence,
            'risk_level': risk_level,
            'action': risk_levels.get(risk_level, {}).get('action', 'AUCUNE'),
            'recommendations': recommendations
        }

    def _generate_recommendations(self, prediction, sensor_data):
        """GÃ©nÃ©ration de recommandations personnalisÃ©es"""
        recommendations = {
            'None': [
                "âœ… SystÃ¨me opÃ©rationnel",
                "ğŸ“… Maintenance planifiÃ©e normale",
                "ğŸ” VÃ©rification de routine programmÃ©e"
            ],
            'Electrical Fault': [
                "ğŸ”Œ VÃ©rifier l'alimentation Ã©lectrique",
                "ğŸ” Inspecter les connexions et cÃ¢bles",
                "âš¡ ContrÃ´ler la stabilitÃ© de tension",
                "ğŸ“Š Analyser les variations de courant"
            ],
            'Mechanical Failure': [
                "ğŸ›‘ ArrÃªt immÃ©diat recommandÃ©",
                "ğŸ”§ Inspection mÃ©canique complÃ¨te",
                "ğŸ“Š VÃ©rifier l'usure des composants",
                "ğŸ¯ ContrÃ´le des niveaux de vibration"
            ],
            'Overheating': [
                "ğŸŒ¡ï¸ RÃ©duire la charge immÃ©diatement",
                "â„ï¸ VÃ©rifier le systÃ¨me de refroidissement",
                "ğŸ”¥ Nettoyer les ventilateurs et radiateurs",
                "ğŸ“ˆ Surveiller la tendance tempÃ©rature"
            ]
        }
        return recommendations.get(prediction, ["ğŸ” Diagnostic Ã  approfondir"])

# --- GÃ‰NÃ‰RATION DE DONNÃ‰ES SIMULÃ‰ES ---
def generate_sample_data():
    """GÃ©nÃ¨re des donnÃ©es IoT simulÃ©es basÃ©es sur votre projet"""
    np.random.seed(42)

    n_samples = 5000
    data = {
        'Sensor_ID': [f'SENSOR_{i:03d}' for i in range(n_samples)],
        'Temperature': np.random.normal(65, 15, n_samples),
        'Vibration': np.random.gamma(2, 2, n_samples),
        'Pressure': np.random.normal(100, 20, n_samples),
        'Voltage': np.random.normal(220, 10, n_samples),
        'Current': np.random.normal(15, 3, n_samples),
        'FFT_Feature1': np.random.uniform(0, 1, n_samples),
        'FFT_Feature2': np.random.uniform(0, 1, n_samples),
        'Timestamp': pd.date_range('2024-01-01', periods=n_samples, freq='H')
    }

    df = pd.DataFrame(data)

    # GÃ©nÃ©ration des dÃ©fauts basÃ©e sur des seuils rÃ©alistes
    conditions = [
        (df['Temperature'] > 85) & (df['Voltage'] < 210),
        (df['Vibration'] > 8) & (df['Pressure'] > 130),
        (df['Temperature'] > 90),
        (df['Current'] > 20)
    ]
    choices = ['Electrical Fault', 'Mechanical Failure', 'Overheating', 'Electrical Fault']

    df['Fault_Type'] = np.select(conditions, choices, default='None')
    df['Fault_Status'] = (df['Fault_Type'] != 'None').astype(int)
    df['Anomaly_Score'] = np.random.uniform(0, 1, n_samples)

    return df

# --- PRÃ‰PARATION DES DONNÃ‰ES ET ENTRAÃNEMENT ---
@st.cache_resource
def load_model_and_data():
    """Charge et entraÃ®ne le modÃ¨le avec mise en cache"""
    st.info("ğŸ¯ GÃ©nÃ©ration des donnÃ©es et entraÃ®nement du modÃ¨le...")

    # GÃ©nÃ©ration des donnÃ©es
    df_clean = generate_sample_data()

    # Feature engineering avancÃ© (basÃ© sur votre projet)
    df_clean['Timestamp'] = pd.to_datetime(df_clean['Timestamp'])
    df_clean['hour'] = df_clean['Timestamp'].dt.hour

    # Features composites (Cellule 13 de votre projet)
    df_clean['thermal_stress'] = df_clean['Temperature'] * df_clean['Current'] / 1000
    df_clean['mechanical_stress'] = df_clean['Vibration'] * df_clean['Pressure'] / 1000
    df_clean['power_consumption'] = df_clean['Voltage'] * df_clean['Current']

    # Normalisation des features
    for col in ['Temperature', 'Vibration', 'Pressure', 'Voltage', 'Current']:
        df_clean[f'Normalized_{col}'] = (
            df_clean[col] - df_clean[col].mean()
        ) / df_clean[col].std()

    # Features finales (basÃ©es sur votre projet)
    features = [
        'Temperature', 'Vibration', 'Pressure', 'Voltage', 'Current',
        'FFT_Feature1', 'FFT_Feature2', 'Anomaly_Score',
        'Normalized_Temp', 'Normalized_Vibration', 'Normalized_Pressure',
        'Normalized_Voltage', 'Normalized_Current', 'hour',
        'thermal_stress', 'mechanical_stress', 'power_consumption'
    ]

    X = df_clean[features]
    y = df_clean['Fault_Type']

    # ModÃ¨le ensemble (Random Forest + XGBoost + SVM)
    rf_model = RandomForestClassifier(
        n_estimators=200,
        max_depth=20,
        min_samples_split=2,
        min_samples_leaf=1,
        random_state=42,
        n_jobs=-1
    )

    xgb_model = XGBClassifier(
        n_estimators=150,
        learning_rate=0.1,
        max_depth=6,
        random_state=42
    )

    svm_model = SVC(
        kernel='rbf',
        probability=True,
        random_state=42
    )

    ensemble_model = VotingClassifier(
        estimators=[
            ('rf', rf_model),
            ('xgb', xgb_model),
            ('svm', svm_model)
        ],
        voting='soft'
    )

    # EntraÃ®nement
    ensemble_model.fit(X, y)

    # SystÃ¨me d'alerte
    alert_system = IntelligentAlertSystem(ensemble_model, features)

    st.success("âœ… ModÃ¨le entraÃ®nÃ© avec succÃ¨s !")
    return alert_system, df_clean, ensemble_model, features

# --- INTERFACE STREAMLIT ---
def main():
    st.title("ğŸ­ SystÃ¨me de Maintenance PrÃ©dictive pour Ã‰quipements IoT")
    st.markdown("**Projet Capstone Data Science - BasÃ© sur votre analyse complÃ¨te**")

    # Sidebar avec informations
    with st.sidebar:
        st.header("ğŸ“Š Ã€ propos")
        st.markdown("""
        **Technologies utilisÃ©es :**
        - Python, Scikit-learn, XGBoost
        - Random Forest, SVM, ModÃ¨le Ensemble
        - Streamlit pour l'interface

        **Types de dÃ©fauts dÃ©tectÃ©s :**
        - âœ… Aucun dÃ©faut
        - ğŸ”Œ DÃ©faut Ã©lectrique
        - ğŸ”§ DÃ©faut mÃ©canique
        - ğŸŒ¡ï¸ Surchauffe
        """)

        st.header("ğŸ¯ Objectifs")
        st.markdown("""
        - Classification multi-classes
        - DÃ©tection temps rÃ©el
        - RÃ©duction des coÃ»ts de maintenance
        - Alertes intelligentes
        """)

    # Chargement du modÃ¨le
    alert_system, df_demo, model, features = load_model_and_data()

    # Onglets principaux
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ” PrÃ©diction Temps RÃ©el",
        "ğŸ“Š Analyse des DonnÃ©es",
        "ğŸ“ˆ Performance ModÃ¨le",
        "ğŸš¨ Historique Alertes"
    ])

    with tab1:
        st.header("PrÃ©diction en Temps RÃ©el")

        col1, col2 = st.columns([1, 1])

        with col1:
            st.subheader("ğŸ“ˆ ParamÃ¨tres du Capteur")

            # SÃ©lection de scÃ©narios prÃ©dÃ©finis
            scenario = st.selectbox(
                "Choisir un scÃ©nario :",
                [
                    "ğŸ¯ Normal (Optimal)",
                    "âš ï¸ DÃ©faut Ã‰lectrique",
                    "ğŸ”§ DÃ©faut MÃ©canique",
                    "ğŸŒ¡ï¸ Surchauffe",
                    "ğŸ”§ PersonnalisÃ©"
                ]
            )

            # Valeurs par dÃ©faut selon le scÃ©nario
            if scenario == "ğŸ¯ Normal (Optimal)":
                temp, vib, press, volt, curr = 65.0, 3.5, 95.0, 220.0, 15.0
            elif scenario == "âš ï¸ DÃ©faut Ã‰lectrique":
                temp, vib, press, volt, curr = 75.0, 4.0, 110.0, 190.0, 22.0
            elif scenario == "ğŸ”§ DÃ©faut MÃ©canique":
                temp, vib, press, volt, curr = 70.0, 9.5, 140.0, 215.0, 16.0
            elif scenario == "ğŸŒ¡ï¸ Surchauffe":
                temp, vib, press, volt, curr = 92.0, 5.0, 105.0, 225.0, 18.0
            else:
                temp, vib, press, volt, curr = 65.0, 3.5, 95.0, 220.0, 15.0

            # ContrÃ´les des paramÃ¨tres
            temperature = st.slider("ğŸŒ¡ï¸ Temperature (Â°C)", 20.0, 120.0, temp, 0.1)
            vibration = st.slider("ğŸ“Š Vibration (m/sÂ²)", 0.0, 15.0, vib, 0.1)
            pressure = st.slider("ğŸ’¨ Pressure (kPa)", 50.0, 200.0, press, 0.1)
            voltage = st.slider("âš¡ Voltage (V)", 180.0, 250.0, volt, 0.1)
            current = st.slider("ğŸ”‹ Current (A)", 5.0, 25.0, curr, 0.1)

            sensor_id = st.text_input("ğŸ”§ ID du Capteur", "SENSOR_001")

        with col2:
            st.subheader("ğŸ¯ RÃ©sultats du Diagnostic")

            if st.button("ğŸš€ Lancer l'Analyse", type="primary", use_container_width=True):
                # PrÃ©paration des donnÃ©es de capteur
                sensor_data = {
                    'Temperature': temperature,
                    'Vibration': vibration,
                    'Pressure': pressure,
                    'Voltage': voltage,
                    'Current': current,
                    'FFT_Feature1': np.random.uniform(0, 1),
                    'FFT_Feature2': np.random.uniform(0, 1),
                    'Anomaly_Score': np.random.uniform(0, 1),
                    'hour': pd.Timestamp.now().hour,
                    'thermal_stress': temperature * current / 1000,
                    'mechanical_stress': vibration * pressure / 1000,
                    'power_consumption': voltage * current
                }

                # Ajout des features normalisÃ©es
                for col in ['Temperature', 'Vibration', 'Pressure', 'Voltage', 'Current']:
                    sensor_data[f'Normalized_{col}'] = 0.0  # SimplifiÃ© pour la dÃ©mo

                # PrÃ©diction
                with st.spinner("ğŸ” Analyse en cours..."):
                    prediction, confidence, proba_dict = alert_system.predict_with_confidence(sensor_data)
                    alert_info = alert_system.evaluate_risk(sensor_id, prediction, confidence, sensor_data)

                # Affichage des rÃ©sultats
                st.subheader("ğŸ“‹ Diagnostic Complet")

                # MÃ©triques principales
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("PrÃ©diction", alert_info['prediction'])
                with col2:
                    risk_color = {
                        'HIGH': 'ğŸ”´', 'MEDIUM': 'ğŸŸ¡', 'LOW': 'ğŸ”µ', 'SAFE': 'ğŸŸ¢'
                    }
                    st.metric("Niveau de Risque",
                             f"{risk_color.get(alert_info['risk_level'], 'âšª')} {alert_info['risk_level']}")
                with col3:
                    st.metric("Confiance", f"{alert_info['confidence']:.1%}")

                # Alerte colorÃ©e
                if alert_info['risk_level'] == 'HIGH':
                    st.error(f"ğŸš¨ **{alert_info['action']}**")
                elif alert_info['risk_level'] == 'MEDIUM':
                    st.warning(f"âš ï¸ **{alert_info['action']}**")
                elif alert_info['risk_level'] == 'LOW':
                    st.info(f"â„¹ï¸ **{alert_info['action']}**")
                else:
                    st.success(f"âœ… **{alert_info['action']}**")

                # Recommandations
                with st.expander("ğŸ“‹ Recommandations dÃ©taillÃ©es", expanded=True):
                    for i, rec in enumerate(alert_info['recommendations'], 1):
                        st.write(f"{i}. {rec}")

                # ProbabilitÃ©s
                with st.expander("ğŸ“Š ProbabilitÃ©s par type de dÃ©faut"):
                    prob_df = pd.DataFrame(proba_dict, index=['ProbabilitÃ©']).T
                    prob_df_sorted = prob_df.sort_values('ProbabilitÃ©', ascending=False)
                    st.dataframe(prob_df_sorted.style.format("{:.1%}"))

                    # Graphique des probabilitÃ©s
                    fig, ax = plt.subplots(figsize=(10, 4))
                    prob_df_sorted.plot(kind='bar', ax=ax, color='skyblue')
                    ax.set_title('Distribution des ProbabilitÃ©s de DÃ©faut')
                    ax.set_ylabel('ProbabilitÃ©')
                    ax.tick_params(axis='x', rotation=45)
                    st.pyplot(fig)

    with tab2:
        st.header("Analyse des DonnÃ©es")

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("ğŸ“ˆ Distribution des DÃ©fauts")
            fault_dist = df_demo['Fault_Type'].value_counts()

            fig, ax = plt.subplots(figsize=(8, 6))
            ax.pie(fault_dist.values, labels=fault_dist.index, autopct='%1.1f%%', startangle=90)
            ax.set_title('RÃ©partition des Types de DÃ©fauts')
            st.pyplot(fig)

        with col2:
            st.subheader("ğŸ“Š Statistiques Descriptives")
            st.dataframe(df_demo[['Temperature', 'Vibration', 'Pressure', 'Voltage', 'Current']].describe())

        # CorrÃ©lations
        st.subheader("ğŸ”— Matrice de CorrÃ©lation")
        numeric_cols = ['Temperature', 'Vibration', 'Pressure', 'Voltage', 'Current', 'Anomaly_Score']
        corr_matrix = df_demo[numeric_cols].corr()

        fig, ax = plt.subplots(figsize=(10, 8))
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=ax)
        ax.set_title('Matrice de CorrÃ©lation')
        st.pyplot(fig)

    with tab3:
        st.header("Performance du ModÃ¨le")

        # Ã‰valuation du modÃ¨le
        X = df_demo[features]
        y = df_demo['Fault_Type']
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Accuracy", f"{accuracy:.1%}")
        with col2:
            st.metric("Nombre d'Ã©chantillons", len(df_demo))
        with col3:
            st.metric("Nombre de features", len(features))

        # Matrice de confusion
        st.subheader("ğŸ“‹ Matrice de Confusion")
        cm = confusion_matrix(y_test, y_pred, labels=model.classes_)

        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_, ax=ax)
        ax.set_xlabel('PrÃ©dit')
        ax.set_ylabel('RÃ©el')
        ax.set_title('Matrice de Confusion')
        st.pyplot(fig)

        # Rapport de classification
        st.subheader("ğŸ“Š Rapport de Classification")
        report = classification_report(y_test, y_pred, output_dict=True)
        report_df = pd.DataFrame(report).transpose()
        st.dataframe(report_df.style.format("{:.2f}"))

    with tab4:
        st.header("Historique des Alertes")
        st.info("ğŸ“ˆ FonctionnalitÃ© en cours de dÃ©veloppement...")

        # Simulation d'historique
        history_data = {
            'Date': pd.date_range('2024-01-01', periods=10, freq='D'),
            'Capteur': [f'SENSOR_{i:03d}' for i in range(10)],
            'Type DÃ©faut': ['None', 'Electrical Fault', 'None', 'Overheating', 'None',
                           'Mechanical Failure', 'None', 'None', 'Electrical Fault', 'None'],
            'Niveau Risque': ['SAFE', 'HIGH', 'SAFE', 'MEDIUM', 'SAFE',
                             'HIGH', 'SAFE', 'SAFE', 'MEDIUM', 'SAFE'],
            'Confiance': [0.95, 0.89, 0.92, 0.76, 0.88, 0.91, 0.94, 0.90, 0.78, 0.93]
        }

        history_df = pd.DataFrame(history_data)
        st.dataframe(history_df)

        # Graphique des alertes
        fig, ax = plt.subplots(figsize=(10, 4))
        alert_counts = history_df['Niveau Risque'].value_counts()
        alert_counts.plot(kind='bar', color=['green', 'red', 'orange', 'blue'], ax=ax)
        ax.set_title('Distribution des Niveaux de Risque')
        ax.set_ylabel('Nombre d\'alertes')
        st.pyplot(fig)

# --- FOOTER ---
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center'>
        <p><strong>Projet Capstone Data Science - Maintenance PrÃ©dictive IoT</strong></p>
        <p>DÃ©veloppÃ© avec â¤ï¸ using Streamlit | BasÃ© sur l'analyse complÃ¨te du dataset IoT</p>
    </div>
    """,
    unsafe_allow_html=True
)

if __name__ == "__main__":
    main()
